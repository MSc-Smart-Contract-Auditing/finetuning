{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "model_name = 'msc-smart-contract-auditing/deepseek-coder-6.7b-vulnerability'\n",
                "model_alias = 'deepseek-coder-6.7b-finetuned'"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from datasets import load_dataset\n",
                "from tqdm import tqdm\n",
                "import csv\n",
                "from pathlib import Path\n",
                "import torch\n",
                "from transformers import AutoTokenizer, AutoModelForCausalLM"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "WORK_DIR = Path(f'/vol/bitbucket/kza23/finetuning/{model_alias}')\n",
                "WORK_DIR.mkdir(exist_ok=True)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
                "model = AutoModelForCausalLM.from_pretrained(\n",
                "    model_name,\n",
                "    trust_remote_code=True,\n",
                "    torch_dtype=torch.bfloat16,\n",
                "    device_map='auto'\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "test_dataset = load_dataset(\n",
                "    \"msc-smart-contract-auditing/audits-with-reasons\",\n",
                "    split=\"test\"\n",
                ")\n",
                "\n",
                "test_dataset"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Descriptions"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "prompt = \\\n",
                "\"\"\"\n",
                "Below are one or more Solidity codeblocks. The codeblocks might contain vulnerable code.\n",
                "If there is a vulnerability please provide a description of the vulnearblity in terms of the code that is responsible for it.\n",
                "Describe how an attacker would be able to take advantage of the vulnerability so the explanation is even more clear.\n",
                "\n",
                "Output only the description of the vulnerability and the attacking vector. No additional information is needed.\n",
                "\n",
                "If there is no vulnerability output \"There is no vulnearbility\".\n",
                "\n",
                "Codeblocks:\n",
                "{}\n",
                "\n",
                "\"\"\""
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "df_test = test_dataset.to_pandas()\n",
                "\n",
                "queries = df_test.apply(lambda row: prompt.format(row['code'].replace('\\\\n', '\\n')), axis=1)\n",
                "\n",
                "print(queries.iloc[0])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "with open(WORK_DIR/\"descriptions.csv\", \"w\", newline=\"\") as f:\n",
                "    writer = csv.writer(f)\n",
                "    writer.writerow([\"id\", \"output\", \"real\"])\n",
                "\n",
                "    for idx, (query, real) in tqdm(enumerate(zip(queries, test_dataset['description'])), total=len(queries)):\n",
                "\n",
                "        messages = [\n",
                "            { 'role': 'user', 'content': query }\n",
                "        ]\n",
                "        inputs = tokenizer.apply_chat_template(messages, add_generation_prompt=True, return_tensors=\"pt\").to(model.device)\n",
                "        outputs = model.generate(inputs, max_new_tokens=512, do_sample=True, top_k=25, top_p=0.95, num_return_sequences=1, eos_token_id=tokenizer.eos_token_id)\n",
                "        description = tokenizer.decode(outputs[0][len(inputs[0]):], skip_special_tokens=True)\n",
                "        # writer.writerow([idx, description, real])\n",
                "        print(description)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Recommendations"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "query_template = \\\n",
                "\"\"\"\n",
                "Below is some solidity code and a description of a vulnerability that the code contains.\n",
                "\n",
                "Explain how to mitigate or fix the vulnerability.\n",
                "Codeblocks:\n",
                "{}\n",
                "\n",
                "Vulnerability:\n",
                "{}\"\"\""
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "df_test = test_dataset.to_pandas()\n",
                "df_test = df_test[df_test['description'].notnull()]\n",
                "queries = df_test.apply(lambda row: query_template.format(row['code'].replace('\\\\n', '\\n'), row['description'].replace('\\\\n', '\\n')), axis=1)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "with open(WORK_DIR/\"recommendations.csv\", \"w\", newline=\"\") as f:\n",
                "    writer = csv.writer(f)\n",
                "    writer.writerow([\"id\", \"output\", \"real\"])\n",
                "\n",
                "    for idx, (query, real) in tqdm(enumerate(zip(queries, test_dataset['recommendation'])), total=len(queries)):\n",
                "\n",
                "        messages = [\n",
                "            { 'role': 'user', 'content': query }\n",
                "        ]\n",
                "        inputs = tokenizer.apply_chat_template(messages, add_generation_prompt=True, return_tensors=\"pt\").to(model.device)\n",
                "        outputs = model.generate(inputs, max_new_tokens=512, do_sample=False, top_k=50, top_p=0.95, num_return_sequences=1, eos_token_id=tokenizer.eos_token_id)\n",
                "        recommendation = tokenizer.decode(outputs[0][len(inputs[0]):], skip_special_tokens=True)\n",
                "        writer.writerow([idx, recommendation, real])"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3 (ipykernel)",
            "language": "python",
            "name": "python3"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
